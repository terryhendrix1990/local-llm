# Local LLM

## Install dependencies on MacOS

Install `ollama`

`brew install ollama`

Then start ollama server.

`ollama serve`

Download a coding model from another tab.

`ollama pull qwen2.5-coder:14b`

Or for larger model with better reasoning ability.

`ollama pull qwen2.5-coder:32b`

Install aider:

`python -m pip install aider-install && aider-install

# References

- [Run aider with docker](https://aider.chat/docs/install/docker.html)
